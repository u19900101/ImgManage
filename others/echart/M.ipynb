{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.从html提取信息写入csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 调用外部的py\r\n",
    "from demo import *\r\n",
    "hello()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.将空缺的日期补齐"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "df=pd.read_csv('../csv绘图/info.csv',header=0,sep=',') #filename可以直接从盘符开始，标明每一级的文件夹直到csv文件，header=None表示头部为空，sep=' '表示数据间使用空格作为分隔符，如果分隔符是逗号，只需换成 ‘，’即可。\r\n",
    "# 2.按日期进行升序排列\r\n",
    "df2 = df.sort_values(by='day')\r\n",
    "# 3.提取出 day列  将其转化为 yyyy/mm/dd的格式  将 str=2017/1/27 23:06  转化为  datetime类型\r\n",
    "d1 = [datetime.strptime(x, '%Y/%m/%d %H:%M') for x in list(df2[\"day\"])]\r\n",
    "#       将 datetime 转化为 str 2017/01/27\r\n",
    "d_2017 = [datetime.strftime(x, '%Y/%m/%d') for x in list(d1)]\r\n",
    "# 4.创建全年的日子\r\n",
    "all_2017=[datetime.strftime(x,'%Y/%m/%d') for x in list(pd.date_range(start='2017/01/01',  end=\"2017/12/31\"))]\r\n",
    "# 5.将上两项做差求出没有记录的日子\r\n",
    "absent_2017 = [i for i in all_2017 if i not in d_2017]\r\n",
    "\r\n",
    "# 6.将没有记录的日子进行补充  [day:当天,title:空,longitude,latitude,num:0]\r\n",
    "dataframe = pd.DataFrame({'day': absent_2017,\r\n",
    "                            'title': [None]*len(absent_2017),\r\n",
    "                            'longitude': [None]*len(absent_2017),\r\n",
    "                            'latitude': [None]*len(absent_2017),\r\n",
    "                            'num': [0]*len(absent_2017)})\r\n",
    "dataframe.to_csv(\"./info.csv\",index=False, sep=',',mode='a', header=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017 = ['2017/07/10','2017/07/12','2017/07/11']\r\n",
    "absent_2017_np = [time.mktime(time.strptime(x, '%Y/%m/%d')) for x in absent_2017]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "import time       \r\n",
    "timeArray = time.strptime('2017/7/11 00:00', '%Y/%m/%d %H:%M')\r\n",
    "#转换成时间戳\r\n",
    "time.mktime(timeArray)     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017_np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.处理重复的日子"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 手动修改日期 并检查查看"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "res_path = './data/我的抗战2.0_2020_info.csv'\r\n",
    "# res_path = './data/2020_info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 手动修改 日期  \r\n",
    "# 截取day的date————2017/02/02  是否唯一进行检查\r\n",
    "M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "# 给原 df加一列 date\r\n",
    "df['day_date'] = M\r\n",
    "# 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "M = day_date[['day','title','day_date']]\r\n",
    "print(len(M))\r\n",
    "M"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2自动整理日期\r\n",
    "2019/08/19 12:00,,,,0,1566187200.0\r\n",
    "2019/08/20 15:02,3.196  转文全部被拒  心情失落  又开始考虑复原,0,0,28,1566284520.0\r\n",
    "2019/08/20 15:04,3.197  第一天便无法做到自律 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def edit_info(res_path):\r\n",
    "    # 手动修改 日期  \r\n",
    "    # 截取day的date————2017/02/02 12:26  -->  2017/02/02  是否唯一进行检查\r\n",
    "    df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "    M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "    # 给原 df加一列 date\r\n",
    "    df['day_date'] = M\r\n",
    "    # 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "    day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "    M = day_date[['day','title','day_date']]\r\n",
    "    print(\"重复的天数为：\",len(M))\r\n",
    "   \r\n",
    "    all_index = M.index.tolist() \r\n",
    "      # 剔除 0 元素\r\n",
    "    if 0 in all_index:\r\n",
    "        all_index.remove(0)\r\n",
    "    # 2.判断 index-1 是否为系统自动生成的 (num值是否为0)\r\n",
    "    del_index = []\r\n",
    "\r\n",
    "    for x in all_index:\r\n",
    "        if ((df[x:x+1].day_date == '2020/02/13').bool()):\r\n",
    "            print(\"2020/02/13\")\r\n",
    "        if ((df[x-1:x].num == 0).bool()):\r\n",
    "            print(\"删除行\",df[x-1:x].day)\r\n",
    "            del_index.append(x-1)\r\n",
    "            # df = df.drop([x-1])\r\n",
    "        # 3.是——删掉 index-1这一行 \r\n",
    "        # 4.修改 df[index] 的 date-1\r\n",
    "            temp = df[x:x+1]\r\n",
    "            dt = datetime.datetime.strptime(temp.at[temp.index.values[0],'day'],'%Y/%m/%d %H:%M')\r\n",
    "            out_date = (dt + datetime.timedelta(days=-1)).strftime('%Y/%m/%d %H:%M')\r\n",
    "            temp.day[x] = out_date\r\n",
    "    # 5.更新csv文件\r\n",
    "    df = df.drop(del_index)\r\n",
    "    df.to_csv(res_path,index=False, sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3将文件按年进行分表"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1.读取文件\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 2.按照day_date(2018/01/01)  列的前四位  2018进行分表\r\n",
    "# day_date_list = list(df['day_date'])\r\n",
    "day_date_list = [x.split('/')[0] for x in list(df['day_date'])]\r\n",
    "year_list = list(set(day_date_list))\r\n",
    "year_list = [eval(x) for x in list(set(day_date_list))]\r\n",
    "# 3.将年份由小到大进行排序\r\n",
    "year_list.sort()\r\n",
    "# 4.分割年份  年份第一次出现的位置进行\r\n",
    "all_years = [df[day_date_list.index(str(year_list[x])):day_date_list.index(str(year_list[x]+1))] for x in range(len(year_list)-1)]\r\n",
    "# 最后一年\r\n",
    "all_years.append(df[day_date_list.index(str(year_list[-1])):])\r\n",
    "# 3.输出表\r\n",
    "[df_year.to_csv(\"./data/\"+str(year)+\"_info.csv\",index=False, sep=',')  for (year,df_year) in zip(year_list,all_years)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4将没有坐标的日子进行临近填充"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "import pandas as pd\r\n",
    "# 1.读取文件\r\n",
    "# res_path = './data/2018_info.csv'\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# df[df.latitude =='0']\r\n",
    "df[df.longitude == '0']\r\n",
    "# df[len(str(df.longitude))]\r\n",
    "# 2.判断数据是否有gps信息  \r\n",
    "# for z in range(259,len(df)):\r\n",
    "#     df['longitude'][z] =  None\r\n",
    "#     df['latitude'][z] =  None\r\n",
    "# # df.to_csv(res_path,index=False, sep=',')\r\n",
    "# 3.根据距离最近 有gps的值进行复制\r\n",
    "# 4.重新写入文件"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [day, title, longitude, latitude, num, day_timestramp, day_date]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>title</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num</th>\n",
       "      <th>day_timestramp</th>\n",
       "      <th>day_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "# 1.读取文件\r\n",
    "# res_path = './data/2018_info.csv'\r\n",
    "res_path = './data/2017_info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "\r\n",
    "# 2.线性分割 坐标\r\n",
    "g = list(df.loc[89:93].longitude)\r\n",
    "# 提取度分秒的数字  # 9°32'45  -->  9*3600+32*60+45\r\n",
    "pattern = re.compile(r'\\d+')\r\n",
    "# res_start = [int(i) for i in pattern.findall(g[0])]\r\n",
    "# res_start = res_start[0]*3600+res_start[1]*60+res_start[2]\r\n",
    "# res_end = [int(i) for i in pattern.findall(g[-1])]\r\n",
    "# res_end = res_end[0]*3600+res_end[1]*60+res_end[2]\r\n",
    "# 上面的表达式简化版\r\n",
    "res_start_end = [[int(i) for i in pattern.findall(x)] for x in [g[0],g[-1]]]\r\n",
    "res_start_end = [x[0]*3600+x[1]*60+x[2] for x in res_start_end]\r\n",
    "res_gps =[str(int(m/3600))+\"°\"+str(int(m%3600/60))+\"'\"+str(int(m%3600%60)) for m in np.linspace(res_start_end[0],res_start_end[1],len(g))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\r\n",
    "import numpy as np\r\n",
    "# 线性分割 坐标\r\n",
    "# 提取度分秒的数字  # 9°32'45  -->  9*3600+32*60+45\r\n",
    "pattern = re.compile(r'\\d+')\r\n",
    "# res_start = [int(i) for i in pattern.findall(g[0])]\r\n",
    "# res_start = res_start[0]*3600+res_start[1]*60+res_start[2]\r\n",
    "# res_end = [int(i) for i in pattern.findall(g[-1])]\r\n",
    "# res_end = res_end[0]*3600+res_end[1]*60+res_end[2]\r\n",
    "# 上面的表达式简化版\r\n",
    "res_start_end = [[int(i) for i in pattern.findall(x)] for x in [g[0],g[-1]]]\r\n",
    "res_start_end = [x[0]*3600+x[1]*60+x[2] for x in res_start_end]\r\n",
    "res_gps =[str(int(m/3600))+\"°\"+str(int(m%3600/60))+\"'\"+str(int(m%3600%60)) for m in np.linspace(res_start_end[0],res_start_end[1],len(g))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cut_gps(gps_df):\r\n",
    "    res = []\r\n",
    "    # 2.线性分割 坐标\r\n",
    "    for g in [list(gps_df.longitude),list(gps_df.latitude)]:\r\n",
    "\r\n",
    "        # 提取度分秒的数字  # 9°32'45  -->  9*3600+32*60+45\r\n",
    "        pattern = re.compile(r'\\d+')\r\n",
    "        # res_start = [int(i) for i in pattern.findall(g[0])]\r\n",
    "        # res_start = res_start[0]*3600+res_start[1]*60+res_start[2]\r\n",
    "        # res_end = [int(i) for i in pattern.findall(g[-1])]\r\n",
    "        # res_end = res_end[0]*3600+res_end[1]*60+res_end[2]\r\n",
    "        # 上面的表达式简化版\r\n",
    "        res_start_end = [[int(i) for i in pattern.findall(x)] for x in [g[0],g[-1]]]\r\n",
    "        res_start_end = [x[0]*3600+x[1]*60+x[2] for x in res_start_end]\r\n",
    "        res_gps =[str(int(m/3600))+\"°\"+str(int(m%3600/60))+\"'\"+str(int(m%3600%60)) for m in np.linspace(res_start_end[0],res_start_end[1],len(g))]\r\n",
    "        res.append(res_gps)\r\n",
    "    return res\r\n",
    "res_path = './data/2017_info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "cut_gps(df.loc[89:93])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "r = \"./mklll/mkname/info.csv\"\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./mklll/mkname'"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 32-bit"
  },
  "interpreter": {
   "hash": "ec7c6df8f2f99fa20fbf736f60336ad208c85ecac47a89374b2e832ec7eb482e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}