{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.从html提取信息写入csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 调用外部的py\r\n",
    "from demo import *\r\n",
    "hello()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.将空缺的日期补齐"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "df=pd.read_csv('../csv绘图/info.csv',header=0,sep=',') #filename可以直接从盘符开始，标明每一级的文件夹直到csv文件，header=None表示头部为空，sep=' '表示数据间使用空格作为分隔符，如果分隔符是逗号，只需换成 ‘，’即可。\r\n",
    "# 2.按日期进行升序排列\r\n",
    "df2 = df.sort_values(by='day')\r\n",
    "# 3.提取出 day列  将其转化为 yyyy/mm/dd的格式  将 str=2017/1/27 23:06  转化为  datetime类型\r\n",
    "d1 = [datetime.strptime(x, '%Y/%m/%d %H:%M') for x in list(df2[\"day\"])]\r\n",
    "#       将 datetime 转化为 str 2017/01/27\r\n",
    "d_2017 = [datetime.strftime(x, '%Y/%m/%d') for x in list(d1)]\r\n",
    "# 4.创建全年的日子\r\n",
    "all_2017=[datetime.strftime(x,'%Y/%m/%d') for x in list(pd.date_range(start='2017/01/01',  end=\"2017/12/31\"))]\r\n",
    "# 5.将上两项做差求出没有记录的日子\r\n",
    "absent_2017 = [i for i in all_2017 if i not in d_2017]\r\n",
    "\r\n",
    "# 6.将没有记录的日子进行补充  [day:当天,title:空,longitude,latitude,num:0]\r\n",
    "dataframe = pd.DataFrame({'day': absent_2017,\r\n",
    "                            'title': [None]*len(absent_2017),\r\n",
    "                            'longitude': [None]*len(absent_2017),\r\n",
    "                            'latitude': [None]*len(absent_2017),\r\n",
    "                            'num': [0]*len(absent_2017)})\r\n",
    "dataframe.to_csv(\"./info.csv\",index=False, sep=',',mode='a', header=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017 = ['2017/07/10','2017/07/12','2017/07/11']\r\n",
    "absent_2017_np = [time.mktime(time.strptime(x, '%Y/%m/%d')) for x in absent_2017]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "import time       \r\n",
    "timeArray = time.strptime('2017/7/11 00:00', '%Y/%m/%d %H:%M')\r\n",
    "#转换成时间戳\r\n",
    "time.mktime(timeArray)     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017_np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.处理重复的日子"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 手动修改日期 并检查查看"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "res_path = './data/我的抗战2.0_2020_info.csv'\r\n",
    "# res_path = './data/2020_info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 手动修改 日期  \r\n",
    "# 截取day的date————2017/02/02  是否唯一进行检查\r\n",
    "M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "# 给原 df加一列 date\r\n",
    "df['day_date'] = M\r\n",
    "# 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "M = day_date[['day','title','day_date']]\r\n",
    "print(len(M))\r\n",
    "M"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2自动整理日期\r\n",
    "2019/08/19 12:00,,,,0,1566187200.0\r\n",
    "2019/08/20 15:02,3.196  转文全部被拒  心情失落  又开始考虑复原,0,0,28,1566284520.0\r\n",
    "2019/08/20 15:04,3.197  第一天便无法做到自律 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def edit_info(res_path):\r\n",
    "    # 手动修改 日期  \r\n",
    "    # 截取day的date————2017/02/02 12:26  -->  2017/02/02  是否唯一进行检查\r\n",
    "    df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "    M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "    # 给原 df加一列 date\r\n",
    "    df['day_date'] = M\r\n",
    "    # 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "    day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "    M = day_date[['day','title','day_date']]\r\n",
    "    print(\"重复的天数为：\",len(M))\r\n",
    "   \r\n",
    "    all_index = M.index.tolist() \r\n",
    "      # 剔除 0 元素\r\n",
    "    if 0 in all_index:\r\n",
    "        all_index.remove(0)\r\n",
    "    # 2.判断 index-1 是否为系统自动生成的 (num值是否为0)\r\n",
    "    del_index = []\r\n",
    "\r\n",
    "    for x in all_index:\r\n",
    "        if ((df[x:x+1].day_date == '2020/02/13').bool()):\r\n",
    "            print(\"2020/02/13\")\r\n",
    "        if ((df[x-1:x].num == 0).bool()):\r\n",
    "            print(\"删除行\",df[x-1:x].day)\r\n",
    "            del_index.append(x-1)\r\n",
    "            # df = df.drop([x-1])\r\n",
    "        # 3.是——删掉 index-1这一行 \r\n",
    "        # 4.修改 df[index] 的 date-1\r\n",
    "            temp = df[x:x+1]\r\n",
    "            dt = datetime.datetime.strptime(temp.at[temp.index.values[0],'day'],'%Y/%m/%d %H:%M')\r\n",
    "            out_date = (dt + datetime.timedelta(days=-1)).strftime('%Y/%m/%d %H:%M')\r\n",
    "            temp.day[x] = out_date\r\n",
    "    # 5.更新csv文件\r\n",
    "    df = df.drop(del_index)\r\n",
    "    df.to_csv(res_path,index=False, sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3将文件按年进行分表"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1.读取文件\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 2.按照day_date(2018/01/01)  列的前四位  2018进行分表\r\n",
    "# day_date_list = list(df['day_date'])\r\n",
    "day_date_list = [x.split('/')[0] for x in list(df['day_date'])]\r\n",
    "year_list = list(set(day_date_list))\r\n",
    "year_list = [eval(x) for x in list(set(day_date_list))]\r\n",
    "# 3.将年份由小到大进行排序\r\n",
    "year_list.sort()\r\n",
    "# 4.分割年份  年份第一次出现的位置进行\r\n",
    "all_years = [df[day_date_list.index(str(year_list[x])):day_date_list.index(str(year_list[x]+1))] for x in range(len(year_list)-1)]\r\n",
    "# 最后一年\r\n",
    "all_years.append(df[day_date_list.index(str(year_list[-1])):])\r\n",
    "# 3.输出表\r\n",
    "[df_year.to_csv(\"./data/\"+str(year)+\"_info.csv\",index=False, sep=',')  for (year,df_year) in zip(year_list,all_years)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4将没有坐标的日子进行临近填充"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# info_path = 'D:\\MyJava\\mylifeImg\\others\\echart\\data\\demo.csv'\r\n",
    "# update_gps_info(info_path)\r\n",
    "dir = 'D:\\MyJava\\mylifeImg\\others\\echart\\data\\\\'\r\n",
    "update_gps_dir(dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 检验填充后的数据是否还有 gps 为 0 或 Nan\r\n",
    "import pandas as pd\r\n",
    "import time\r\n",
    "info_path = '../info.csv'\r\n",
    "m=pd.read_csv(info_path,header=0,sep=',') \r\n",
    "day_date = m[(m['longitude'].isna()) | (m['longitude']=='0')]['day_date']\r\n",
    "for x in day_date:\r\n",
    "    if time.strptime(x, '%Y/%m/%d')<time.localtime():\r\n",
    "        print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 32-bit"
  },
  "interpreter": {
   "hash": "ec7c6df8f2f99fa20fbf736f60336ad208c85ecac47a89374b2e832ec7eb482e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}