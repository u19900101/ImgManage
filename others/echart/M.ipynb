{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.从html提取信息写入csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 调用外部的py\r\n",
    "from demo import *\r\n",
    "hello()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.将空缺的日期补齐"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "df=pd.read_csv('../csv绘图/info.csv',header=0,sep=',') #filename可以直接从盘符开始，标明每一级的文件夹直到csv文件，header=None表示头部为空，sep=' '表示数据间使用空格作为分隔符，如果分隔符是逗号，只需换成 ‘，’即可。\r\n",
    "# 2.按日期进行升序排列\r\n",
    "df2 = df.sort_values(by='day')\r\n",
    "# 3.提取出 day列  将其转化为 yyyy/mm/dd的格式  将 str=2017/1/27 23:06  转化为  datetime类型\r\n",
    "d1 = [datetime.strptime(x, '%Y/%m/%d %H:%M') for x in list(df2[\"day\"])]\r\n",
    "#       将 datetime 转化为 str 2017/01/27\r\n",
    "d_2017 = [datetime.strftime(x, '%Y/%m/%d') for x in list(d1)]\r\n",
    "# 4.创建全年的日子\r\n",
    "all_2017=[datetime.strftime(x,'%Y/%m/%d') for x in list(pd.date_range(start='2017/01/01',  end=\"2017/12/31\"))]\r\n",
    "# 5.将上两项做差求出没有记录的日子\r\n",
    "absent_2017 = [i for i in all_2017 if i not in d_2017]\r\n",
    "\r\n",
    "# 6.将没有记录的日子进行补充  [day:当天,title:空,longitude,latitude,num:0]\r\n",
    "dataframe = pd.DataFrame({'day': absent_2017,\r\n",
    "                            'title': [None]*len(absent_2017),\r\n",
    "                            'longitude': [None]*len(absent_2017),\r\n",
    "                            'latitude': [None]*len(absent_2017),\r\n",
    "                            'num': [0]*len(absent_2017)})\r\n",
    "dataframe.to_csv(\"./info.csv\",index=False, sep=',',mode='a', header=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017 = ['2017/07/10','2017/07/12','2017/07/11']\r\n",
    "absent_2017_np = [time.mktime(time.strptime(x, '%Y/%m/%d')) for x in absent_2017]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "import time       \r\n",
    "timeArray = time.strptime('2017/7/11 00:00', '%Y/%m/%d %H:%M')\r\n",
    "#转换成时间戳\r\n",
    "time.mktime(timeArray)     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "absent_2017_np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.处理重复的日子"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 手动修改日期 并检查查看"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "# First：找到没有进行创作的日子\r\n",
    "# 1.读取文件 第一行为列名称\r\n",
    "res_path = './data/我的抗战2.0_2020_info.csv'\r\n",
    "# res_path = './data/2020_info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 手动修改 日期  \r\n",
    "# 截取day的date————2017/02/02  是否唯一进行检查\r\n",
    "M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "# 给原 df加一列 date\r\n",
    "df['day_date'] = M\r\n",
    "# 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "M = day_date[['day','title','day_date']]\r\n",
    "print(len(M))\r\n",
    "M"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2自动整理日期\r\n",
    "2019/08/19 12:00,,,,0,1566187200.0\r\n",
    "2019/08/20 15:02,3.196  转文全部被拒  心情失落  又开始考虑复原,0,0,28,1566284520.0\r\n",
    "2019/08/20 15:04,3.197  第一天便无法做到自律 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def edit_info(res_path):\r\n",
    "    # 手动修改 日期  \r\n",
    "    # 截取day的date————2017/02/02 12:26  -->  2017/02/02  是否唯一进行检查\r\n",
    "    df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "    M = [x.split(\" \")[0] for x in df[\"day\"].tolist()]\r\n",
    "    # 给原 df加一列 date\r\n",
    "    df['day_date'] = M\r\n",
    "    # 得到date重复的行  保留出现第一次的值  duplicated(keep=False)\r\n",
    "    day_date = df[df['day_date'].duplicated(keep=False)]\r\n",
    "    M = day_date[['day','title','day_date']]\r\n",
    "    print(\"重复的天数为：\",len(M))\r\n",
    "   \r\n",
    "    all_index = M.index.tolist() \r\n",
    "      # 剔除 0 元素\r\n",
    "    if 0 in all_index:\r\n",
    "        all_index.remove(0)\r\n",
    "    # 2.判断 index-1 是否为系统自动生成的 (num值是否为0)\r\n",
    "    del_index = []\r\n",
    "\r\n",
    "    for x in all_index:\r\n",
    "        if ((df[x:x+1].day_date == '2020/02/13').bool()):\r\n",
    "            print(\"2020/02/13\")\r\n",
    "        if ((df[x-1:x].num == 0).bool()):\r\n",
    "            print(\"删除行\",df[x-1:x].day)\r\n",
    "            del_index.append(x-1)\r\n",
    "            # df = df.drop([x-1])\r\n",
    "        # 3.是——删掉 index-1这一行 \r\n",
    "        # 4.修改 df[index] 的 date-1\r\n",
    "            temp = df[x:x+1]\r\n",
    "            dt = datetime.datetime.strptime(temp.at[temp.index.values[0],'day'],'%Y/%m/%d %H:%M')\r\n",
    "            out_date = (dt + datetime.timedelta(days=-1)).strftime('%Y/%m/%d %H:%M')\r\n",
    "            temp.day[x] = out_date\r\n",
    "    # 5.更新csv文件\r\n",
    "    df = df.drop(del_index)\r\n",
    "    df.to_csv(res_path,index=False, sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3将文件按年进行分表"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1.读取文件\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 2.按照day_date(2018/01/01)  列的前四位  2018进行分表\r\n",
    "# day_date_list = list(df['day_date'])\r\n",
    "day_date_list = [x.split('/')[0] for x in list(df['day_date'])]\r\n",
    "year_list = list(set(day_date_list))\r\n",
    "year_list = [eval(x) for x in list(set(day_date_list))]\r\n",
    "# 3.将年份由小到大进行排序\r\n",
    "year_list.sort()\r\n",
    "# 4.分割年份  年份第一次出现的位置进行\r\n",
    "all_years = [df[day_date_list.index(str(year_list[x])):day_date_list.index(str(year_list[x]+1))] for x in range(len(year_list)-1)]\r\n",
    "# 最后一年\r\n",
    "all_years.append(df[day_date_list.index(str(year_list[-1])):])\r\n",
    "# 3.输出表\r\n",
    "[df_year.to_csv(\"./data/\"+str(year)+\"_info.csv\",index=False, sep=',')  for (year,df_year) in zip(year_list,all_years)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4将没有坐标的日子进行临近填充"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# info_path = 'D:\\MyJava\\mylifeImg\\others\\echart\\data\\demo.csv'\r\n",
    "# update_gps_info(info_path)\r\n",
    "dir = 'D:\\MyJava\\mylifeImg\\others\\echart\\data\\\\'\r\n",
    "update_gps_dir(dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 检验填充后的数据是否还有 gps 为 0 或 Nan\r\n",
    "import pandas as pd\r\n",
    "import time\r\n",
    "info_path = '../info.csv'\r\n",
    "m=pd.read_csv(info_path,header=0,sep=',') \r\n",
    "day_date = m[(m['longitude'].isna()) | (m['longitude']=='0')]['day_date']\r\n",
    "for x in day_date:\r\n",
    "    if time.strptime(x, '%Y/%m/%d')<time.localtime():\r\n",
    "        print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.地图视角"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 历史gps的热力图\r\n",
    "var heatmapData = [{\r\n",
    "\t\"lng\": 116.191031,\r\n",
    "\t\"lat\": 39.988585,\r\n",
    "\t\"count\": 10\r\n",
    "}, {\r\n",
    "\t\"lng\": 116.389275,\r\n",
    "\t\"lat\": 39.925818,\r\n",
    "\t\"count\": 11\r\n",
    "}]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1.制作生成形如上述的mapData.js文件，引入到html中即可\r\n",
    "# 2.读取 csv文件的经纬度信息\r\n",
    "import pandas as pd\r\n",
    "# res_path = './data/2017_info.csv'\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 3.对经纬度进行 计数统计\r\n",
    "# df = df.tail(10)\r\n",
    "m = df.groupby(['longitude','latitude']).count()\r\n",
    "\r\n",
    "# 4.输出到js文件\r\n",
    "# \"lng\": 116.191031, \"lat\": 39.988585, \"count\": 10\r\n",
    "# 将 index 设置为列\r\n",
    "m = m.reset_index()\r\n",
    "df = pd.DataFrame(columns = ['lng','lat','count'])\r\n",
    "df[['lng','lat','count']] = m[['longitude','latitude','day']]\r\n",
    "heatmapData = \"var heatmapData_local = \" + df.to_json(orient = 'records')\r\n",
    "# print(heatmapData)\r\n",
    "# 打开一个文件\r\n",
    "fo = open(\"./data/heatmapData_local.js\", \"w\")\r\n",
    "fo.write(heatmapData)\r\n",
    "# 关闭打开的文件\r\n",
    "fo.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2把日记标注在地图上"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# 1.制作生成形如上述的mapData.js文件，引入到html中即可\r\n",
    "# 2.读取 csv文件的经纬度信息\r\n",
    "import pandas as pd\r\n",
    "# res_path = './data/2017_info.csv'\r\n",
    "res_path = '../info.csv'\r\n",
    "df=pd.read_csv(res_path,header=0,sep=',') \r\n",
    "# 3.将需要在地图上显示信息 day title longitude latitude输出到js文件\r\n",
    "\r\n",
    "d = pd.DataFrame(columns = ['lng','lat','day','title'])\r\n",
    "d[['lng','lat','day','title']] = df[['longitude','latitude','day','title']]\r\n",
    "# print(heatmapData)\r\n",
    "# 打开一个文件\r\n",
    "with open('./data/diarymapData.js', 'w', encoding='utf-8') as file:\r\n",
    "    diarymapData = \"var diarymapData = \" + d.to_json(orient = 'records',force_ascii=False)\r\n",
    "   \r\n",
    "    file.write(diarymapData)\r\n",
    "    # 关闭打开的文件\r\n",
    "    file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "d = {'name': '张三', 'age': '1'}\r\n",
    "print(d) \r\n",
    "jd = d.to_json()\r\n",
    "jd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'name': '张三', 'age': '1'}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_json'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-0ffd73da765b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'张三'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mjd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_json'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# day,title,longitude,latitude\r\n",
    "df[['day','title']]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   day title\n",
       "0     2017/01/01 12:00   NaN\n",
       "1     2017/01/02 12:00   NaN\n",
       "2     2017/01/03 12:00   NaN\n",
       "3     2017/01/04 12:00   NaN\n",
       "4     2017/01/05 12:00   NaN\n",
       "...                ...   ...\n",
       "1881  2021/12/27 12:00   NaN\n",
       "1882  2021/12/28 12:00   NaN\n",
       "1883  2021/12/29 12:00   NaN\n",
       "1884  2021/12/30 12:00   NaN\n",
       "1885  2021/12/31 12:00   NaN\n",
       "\n",
       "[1886 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017/01/01 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/01/02 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/01/03 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/01/04 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/01/05 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>2021/12/27 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2021/12/28 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>2021/12/29 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>2021/12/30 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>2021/12/31 12:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1886 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 32-bit"
  },
  "interpreter": {
   "hash": "ec7c6df8f2f99fa20fbf736f60336ad208c85ecac47a89374b2e832ec7eb482e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}